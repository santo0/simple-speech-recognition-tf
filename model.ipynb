{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c0d04d",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# Set seed for experiment reproducibility\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c05ce1",
   "metadata": {},
   "source": [
    "Load the TensorBoard notebook extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c391401-09f0-474a-8d2b-7ad5a74e8870",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbeb6c",
   "metadata": {},
   "source": [
    "Clear any logs from previous runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea3bef4-82aa-491f-aecd-9b9eb8a02fa9",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"rm\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "! rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee09252",
   "metadata": {},
   "source": [
    "For speed purposes, we will only tune three hyperparameters: each hyperparameter will have two alternatives.\n",
    "+ `HP_DROPOUT` = {0.1, 0.25}\n",
    "+ `HP_NUM_UNITS` = {64, 128}\n",
    "+ `HP_OPTIMIZER` = {adam, sgd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88eb33bc-57f6-431e-b3d3-7e7632bf7f59",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([64, 128]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.25))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7274d4f",
   "metadata": {},
   "source": [
    "The code below is explained in `eda.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db64cf22",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('data/mini_speech_commands')\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'mini_speech_commands.zip',\n",
    "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eccc2caf",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "commands = commands[commands != 'README.md']\n",
    "\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "\n",
    "train_files = filenames[:6400]\n",
    "val_files = filenames[6400: 6400 + 800]\n",
    "test_files = filenames[-800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4af22cf",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary):\n",
    "  audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "  return tf.squeeze(audio, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60eca807",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  return parts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40fec25f",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def get_waveform_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  audio_binary = tf.io.read_file(file_path)\n",
    "  waveform = decode_audio(audio_binary)\n",
    "  return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6096037",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3ecc27b",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  # Padding for files with less than 16000 samples\n",
    "  zero_padding = tf.zeros([16000] - tf.shape(waveform), dtype=tf.float32)\n",
    "\n",
    "  # Concatenate audio with padding so that all audio clips will be of the \n",
    "  # same length\n",
    "  waveform = tf.cast(waveform, tf.float32)\n",
    "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "  spectrogram = tf.signal.stft(\n",
    "      equal_length, frame_length=255, frame_step=128)\n",
    "\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f606e9cd",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def get_spectrogram_and_label_id(audio, label):\n",
    "  spectrogram = get_spectrogram(audio)\n",
    "  spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "  label_id = tf.argmax(label == commands)\n",
    "  return spectrogram, label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5028ddee",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "spectrogram_ds = waveform_ds.map(\n",
    "    get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d736000a",
   "metadata": {},
   "source": [
    "## Dataset preprocessing\n",
    "\n",
    "We convert all the audio files to its respective spectrograms and get its labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "036b682c",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(files):\n",
    "  files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "  output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "  output_ds = output_ds.map(\n",
    "      get_spectrogram_and_label_id,  num_parallel_calls=AUTOTUNE)\n",
    "  return output_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a662753e",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "train_ds = preprocess_dataset(train_files)\n",
    "val_ds = preprocess_dataset(val_files)\n",
    "test_ds = preprocess_dataset(test_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91edd442",
   "metadata": {},
   "source": [
    "A batch is a set of samples that will be used to improve the model in the training.\n",
    "\n",
    "Its size is 64 because it's recommended to use a power of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb6c5b85",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "val_ds = val_ds.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a1726",
   "metadata": {},
   "source": [
    "`cache()` and `prefetch` operations reduces read latency while training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bccf77",
   "metadata": {
    "collapsed": true,
    "gradient": {}
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-af0659add037>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f5bfc",
   "metadata": {},
   "source": [
    "Here we define the input shape for the Neural Network and the Normalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80b39a71-56e7-4551-827d-501c63ceb61a",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (124, 129, 1)\n"
     ]
    }
   ],
   "source": [
    "for spectrogram, _ in spectrogram_ds.take(1):\n",
    "  input_shape = spectrogram.shape\n",
    "print('Input shape:', input_shape)\n",
    "num_labels = len(commands)\n",
    "\n",
    "norm_layer = preprocessing.Normalization()\n",
    "norm_layer.adapt(spectrogram_ds.map(lambda x, _: x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f6d65",
   "metadata": {},
   "source": [
    "## Initial model\n",
    "This is the model definied in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d8d9da-7cfe-4655-8dd7-c4afe0cb1d48",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def get_initial_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        preprocessing.Resizing(32, 32), \n",
    "        norm_layer,\n",
    "        layers.Conv2D(32, 3, activation='relu'),\n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.25), #dropout of units: avoids overfitting and generalizes more\n",
    "        layers.Flatten(), #convert n-dimension input to 1-dimension output\n",
    "        layers.Dense(128, activation='relu'),#Full-conected layer\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_labels),#output\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2f9fdc",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "This function will be called when tuning hyperparameters.\n",
    "\n",
    "The hyperparameters that will be tuned are:\n",
    "+ `HP_DROPOUT` for the dropout layers.\n",
    "+ `HP_NUM_UNITS` for the full-connected layer/dense.\n",
    "+ `HP_OPTIMIZER` for the training optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec586788-073f-4c13-873a-2e9dedc9efd5",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def train_test_model_hparams(hparams):\n",
    "    print(input_shape)\n",
    "    model = models.Sequential([\n",
    "        layers.InputLayer(input_shape=input_shape),\n",
    "        preprocessing.Resizing(32, 32), \n",
    "        norm_layer,\n",
    "        layers.Conv2D(32, 3, activation='relu'),\n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        layers.Conv2D(128, 3, activation='relu'),\n",
    "        layers.Conv2D(256, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(hparams[HP_NUM_UNITS], activation='relu'),\n",
    "        layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        layers.Dense(num_labels),\n",
    "    ])\n",
    "    model.compile(\n",
    "          optimizer=hparams[HP_OPTIMIZER],\n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'],\n",
    "    )\n",
    "    model.fit(train_ds, \n",
    "              validation_data=val_ds,  \n",
    "              batch_size=64, \n",
    "              epochs=10,\n",
    "              callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2))\n",
    "    print(\"Finished training\")\n",
    "    _test_ds = test_ds.batch(batch_size)\n",
    "    _test_ds = _test_ds.cache().prefetch(AUTOTUNE)\n",
    "    _, accuracy = model.evaluate(_test_ds)\n",
    "    print(\"Finished evaluation\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e786e71b-76b4-4092-be51-44d523cee047",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model_hparams(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb098aa",
   "metadata": {},
   "source": [
    "### Caution!!!\n",
    "Take a cup of coffe or go outside to take a walk, because tuning the hyperparametrs can take some time.\n",
    "\n",
    "What does this chunk of code is run all of the combinations of hyperparameters defined before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9711332f-6016-4e3a-a374-ee36ec2f59ec",
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "(124, 129, 1)\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 41s 402ms/step - loss: 3.2270 - accuracy: 0.1209 - val_loss: 2.0794 - val_accuracy: 0.1412\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 35s 351ms/step - loss: 2.1119 - accuracy: 0.1291 - val_loss: 2.0794 - val_accuracy: 0.1462\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 2.0906 - accuracy: 0.1270 - val_loss: 2.0794 - val_accuracy: 0.1125\n",
      "Epoch 00003: early stopping\n",
      "Finished training\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 2.0794 - accuracy: 0.1300\n",
      "Finished evaluation\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "(124, 129, 1)\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 2.6712 - accuracy: 0.1198 - val_loss: 2.0794 - val_accuracy: 0.1250\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 39s 391ms/step - loss: 2.0905 - accuracy: 0.1227 - val_loss: 2.0794 - val_accuracy: 0.1250\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 40s 405ms/step - loss: 2.0860 - accuracy: 0.1227 - val_loss: 2.0794 - val_accuracy: 0.1250\n",
      "Epoch 00003: early stopping\n",
      "Finished training\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 2.0794 - accuracy: 0.1437\n",
      "Finished evaluation\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 64, 'dropout': 0.25, 'optimizer': 'adam'}\n",
      "(124, 129, 1)\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 38s 367ms/step - loss: 2.5319 - accuracy: 0.1314 - val_loss: 2.0794 - val_accuracy: 0.1275\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 2.0910 - accuracy: 0.1269 - val_loss: 2.0794 - val_accuracy: 0.1412\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 35s 347ms/step - loss: 2.0972 - accuracy: 0.1262 - val_loss: 2.0794 - val_accuracy: 0.1187\n",
      "Epoch 00003: early stopping\n",
      "Finished training\n",
      "13/13 [==============================] - 2s 122ms/step - loss: 2.0794 - accuracy: 0.1163\n",
      "Finished evaluation\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 64, 'dropout': 0.25, 'optimizer': 'sgd'}\n",
      "(124, 129, 1)\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 34s 333ms/step - loss: 2.2556 - accuracy: 0.1273 - val_loss: 2.0794 - val_accuracy: 0.1112\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 33s 333ms/step - loss: 2.0794 - accuracy: 0.1248 - val_loss: 2.0794 - val_accuracy: 0.1112\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 33s 332ms/step - loss: 2.1010 - accuracy: 0.1270 - val_loss: 2.0794 - val_accuracy: 0.1138\n",
      "Epoch 00003: early stopping\n",
      "Finished training\n",
      "13/13 [==============================] - 2s 123ms/step - loss: 2.0794 - accuracy: 0.1462\n",
      "Finished evaluation\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 128, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "(124, 129, 1)\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 34s 334ms/step - loss: 2.2566 - accuracy: 0.1213 - val_loss: 2.0794 - val_accuracy: 0.1275\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 33s 335ms/step - loss: 2.0816 - accuracy: 0.1264 - val_loss: 2.0794 - val_accuracy: 0.1275\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 2.0794 - accuracy: 0.1264 - val_loss: 2.0794 - val_accuracy: 0.1275\n",
      "Epoch 00003: early stopping\n",
      "Finished training\n",
      "13/13 [==============================] - 2s 122ms/step - loss: 2.0794 - accuracy: 0.1200\n",
      "Finished evaluation\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 128, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "(124, 129, 1)\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 35s 343ms/step - loss: 4.2016 - accuracy: 0.1241 - val_loss: 2.0794 - val_accuracy: 0.1250\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 33s 335ms/step - loss: 2.0845 - accuracy: 0.1280 - val_loss: 2.0794 - val_accuracy: 0.1250\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 34s 339ms/step - loss: 2.0825 - accuracy: 0.1209 - val_loss: 2.0794 - val_accuracy: 0.1163\n",
      "Epoch 00003: early stopping\n",
      "Finished training\n",
      "13/13 [==============================] - 2s 119ms/step - loss: 2.0794 - accuracy: 0.1013\n",
      "Finished evaluation\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 128, 'dropout': 0.25, 'optimizer': 'adam'}\n",
      "(124, 129, 1)\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 35s 340ms/step - loss: 2.4140 - accuracy: 0.1345 - val_loss: 2.0799 - val_accuracy: 0.1163\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 34s 344ms/step - loss: 2.0935 - accuracy: 0.1280 - val_loss: 2.0794 - val_accuracy: 0.1163\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 34s 338ms/step - loss: 2.0960 - accuracy: 0.1302 - val_loss: 2.0794 - val_accuracy: 0.1250\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 34s 339ms/step - loss: 2.0873 - accuracy: 0.1330 - val_loss: 2.0794 - val_accuracy: 0.1225\n",
      "Epoch 00004: early stopping\n",
      "Finished training\n",
      "13/13 [==============================] - 2s 121ms/step - loss: 2.0794 - accuracy: 0.1700\n",
      "Finished evaluation\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 128, 'dropout': 0.25, 'optimizer': 'sgd'}\n",
      "(124, 129, 1)\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 35s 340ms/step - loss: 3.0505 - accuracy: 0.1273 - val_loss: 2.0794 - val_accuracy: 0.1262\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 34s 337ms/step - loss: 2.1057 - accuracy: 0.1267 - val_loss: 2.0794 - val_accuracy: 0.1262\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 34s 337ms/step - loss: 2.0950 - accuracy: 0.1267 - val_loss: 2.0794 - val_accuracy: 0.1262\n",
      "Epoch 00003: early stopping\n",
      "Finished training\n",
      "13/13 [==============================] - 2s 123ms/step - loss: 2.0794 - accuracy: 0.1100\n",
      "Finished evaluation\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "      hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "      }\n",
    "      run_name = \"run-%d\" % session_num\n",
    "      print('--- Starting trial: %s' % run_name)\n",
    "      print({h.name: hparams[h] for h in hparams})\n",
    "      run('logs/hparam_tuning/' + run_name, hparams)\n",
    "      session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b6fff",
   "metadata": {},
   "source": [
    "## TensorBoard\n",
    "\n",
    "Here you can execute TensorBoard using the logs created previously. \n",
    "\n",
    "TensorBoard can be used to visualize the model. In our case we will be using it to visualize the results of hyperparameter tuning done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af6ae63e-0221-455c-bb4d-bdaf3ebef5e0",
   "metadata": {
    "collapsed": true,
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4b5e2a97cc4195d9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4b5e2a97cc4195d9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6366;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning --port=6366"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725dc974",
   "metadata": {},
   "source": [
    "## Custom model\n",
    "\n",
    "Hyperparameters from the previous tuning and added some new layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4be22b2b-f9f1-45bb-8acd-974924d99247",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def get_custom_model():\n",
    "    model = models.Sequential([\n",
    "        layers.InputLayer(input_shape=input_shape),\n",
    "        preprocessing.Resizing(64, 64), \n",
    "        norm_layer,\n",
    "        layers.Conv2D(32, 3, activation='relu'),\n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv2D(128, 3, activation='relu'),\n",
    "        layers.Conv2D(256, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(num_labels),\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9702fd",
   "metadata": {},
   "source": [
    "## Training and testing\n",
    "\n",
    "This function compiles, trains and tests the given model.\n",
    "\n",
    "It trains with 100 epochs, but because we are using `tf.keras.callbacks.EarlyStopping`, the program will know in which epoch to stop. It usually stops at 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92047d97-9c9b-4c23-b295-4ec4995ea71c",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def train_test_model(model):\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    EPOCHS = 100\n",
    "    history = model.fit(train_ds, \n",
    "              validation_data=val_ds,  \n",
    "              batch_size=64, \n",
    "              epochs=EPOCHS,\n",
    "              callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2))\n",
    "    print(\"Finished training\")\n",
    "    \n",
    "    metrics = history.history\n",
    "    plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "    plt.legend(['loss', 'val_loss'])\n",
    "    plt.show()\n",
    "    \n",
    "    _test_ds = test_ds.batch(batch_size)\n",
    "    _test_ds = _test_ds.cache().prefetch(AUTOTUNE)\n",
    "    _, accuracy = model.evaluate(_test_ds)\n",
    "    print(\"Finished evaluation\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9835e",
   "metadata": {},
   "source": [
    "Here you can select which model to train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "341a3a07-918f-4f52-ada0-5ec76d292820",
   "metadata": {
    "collapsed": true,
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resizing_9 (Resizing)        (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "normalization_1 (Normalizati (None, 64, 64, 1)         3         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 26, 26, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               5537920   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 5,926,795\n",
      "Trainable params: 5,926,792\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      " 22/100 [=====>........................] - ETA: 2:18 - loss: 1.9868 - accuracy: 0.2536"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-7204f1dd978a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#model = get_initial_model()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_custom_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Test set accuracy: {test_acc:.0%}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-9f93ecc4890a>\u001b[0m in \u001b[0;36mtrain_test_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      6\u001b[0m     )\n\u001b[0;32m      7\u001b[0m     \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     history = model.fit(train_ds, \n\u001b[0m\u001b[0;32m      9\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_apai\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_apai\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_apai\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_apai\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_apai\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_apai\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_apai\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model = get_initial_model()\n",
    "model = get_custom_model()\n",
    "test_acc = train_test_model(model)\n",
    "print(f'Test set accuracy: {test_acc:.0%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c626609",
   "metadata": {},
   "source": [
    "## Results visualization\n",
    "Here a heatmap of the given model is created. It tests with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1352015e-137a-4808-b48a-d379492bd8b5",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def print_model_test_heatmap(model):\n",
    "    test_audio = []\n",
    "    test_labels = []\n",
    "\n",
    "    for audio, label in test_ds:\n",
    "        test_audio.append(audio.numpy())\n",
    "        test_labels.append(label.numpy())\n",
    "\n",
    "    test_audio = np.array(test_audio)\n",
    "    test_labels = np.array(test_labels)  \n",
    "\n",
    "    y_pred = np.argmax(model.predict(test_audio), axis=1)\n",
    "    y_true = test_labels\n",
    "\n",
    "    test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "    #print(f'Test set accuracy: {test_acc:.0%}')\n",
    "    confusion_mtx = tf.math.confusion_matrix(y_true, y_pred) \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(confusion_mtx, xticklabels=commands, yticklabels=commands, \n",
    "            annot=True, fmt='g')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a67cac1f",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_model_test_heatmap(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
